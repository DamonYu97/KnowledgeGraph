{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Single Source EB Dataframe to RDF\n",
    "\n",
    "This notebook creates rdf triples from EB dataframe based on the [Heritage Text Ontology](https://github.com/frances-ai/HeritageTextOntology), and export it as ttl file. It will only take dataframe whose text content was extracted from single source for each edition. That's to say, one EB term will only have one original description."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and check dataframe\n",
    "\n",
    "Per entry in dataframes, it should have the following columns (see an example of one entry of the first edition):\n",
    "\n",
    "- MMSID:\n",
    "- editor:                                                  Smellie, William\n",
    "- editor_date:                                                   1740-1795\n",
    "- genre:                                                       encyclopedia\n",
    "- language:                                                             eng\n",
    "- termsOfAddress:                                                       NaN\n",
    "- physicalDescription:               3 v., 160 plates : ill. ; 26 cm. (4to)\n",
    "- place:                                                         Edinburgh\n",
    "- publisher:              Printed for A. Bell and C. Macfarquhar; and so...\n",
    "- referencedBy:           [Alston, R.C.  Engl. language III, 560, ESTC T...\n",
    "- shelfLocator:                                                        EB.1\n",
    "- editionSubTitle:        Illustrated with one hundred and sixty copperp...\n",
    "- volumeTitle:            Encyclopaedia Britannica; or, A dictionary of ...\n",
    "- year:                                                                1771\n",
    "- volumeId:                                                       144133901\n",
    "- permanentURL:                            https://digital.nls.uk/144133901\n",
    "- publisherPersons:                     [C. Macfarquhar, Colin Macfarquhar]\n",
    "- volumeNum:                                                              1\n",
    "- letters:                                                              A-B\n",
    "- part:                                                                   0\n",
    "- editionNum:                                                             1\n",
    "- supplementTitle:\n",
    "- supplementSubTitle:\n",
    "- supplementsTo:                                                         []\n",
    "- term:                                                                  OR\n",
    "- definition:             A NEW A D I C T I A A, the name of several riv...\n",
    "- reference_terms:                                                          []\n",
    "- header:                                           EncyclopaediaBritannica\n",
    "- startsAt:                                                              15\n",
    "- endsAt:                                                                15\n",
    "- position:                                                           0\n",
    "- termType:                                                         Article\n",
    "- filePath:                                  144133901/alto/188082904.34.xml"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "23970"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Nineteenth-Century Knowledge Project Dataframe\n",
    "df = pd.read_json('../../source_dataframes/eb/nckp_final_eb_7_dataframe_clean_Damon', orient=\"index\")\n",
    "df =df.fillna(0)\n",
    "\n",
    "len(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9910796273804340]\n"
     ]
    }
   ],
   "source": [
    "edition_mmsids = df[\"MMSID\"].unique()\n",
    "print(edition_mmsids)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "df.rename(columns={'editionTitle': 'volumeTitle', 'volumeTitle': 'editionTitle'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "               term                                               note  \\\n0                 A                                                  0   \n1                 A                                                  0   \n2                AA                                                  0   \n3                AA                                                  0   \n4                AA                                                  0   \n...             ...                                                ...   \n23965  ZWENIGORODKA                                                  0   \n23966       ZWICKAU                                                  0   \n23967        ZWOLLE                                                  0   \n23968        ZYGHUR                                                  0   \n23969   ZYMOSIMETER  formed from ζύμωσις , fermentation, and μέτϑον...   \n\n      alter_names reference_terms  \\\n0              []              []   \n1              []              []   \n2              []              []   \n3              []              []   \n4              []              []   \n...           ...             ...   \n23965          []              []   \n23966          []              []   \n23967          []              []   \n23968          []              []   \n23969          []              []   \n\n                                              definition  startsAt  endsAt  \\\n0      The first letter of the alphabet in every know...        11      12   \n1      as an abbreviation, is likewise of frequent oc...        12      12   \n2      a river of the province of Groningen, in the k...        12      12   \n3      a river in the province of Overyssel. in the N...        12      12   \n4      a river of the province of Antwerp, in the Net...        12      12   \n...                                                  ...       ...     ...   \n23965  a circle of the Russian government of Kiew. It...      1037    1037   \n23966  a city of the kingdom of Saxony, the capital o...      1037    1037   \n23967  a city, the capital of the circle of the same ...      1037    1037   \n23968  a town of Hindustan, in the province of Bejapo...      1037    1037   \n23969  is the name given to an instrument described b...      1037    1037   \n\n       position termType                                        filePath  ...  \\\n0             1  Article   ./eb07_TXT_v2/a2/kp-eb0702-000101-9822-v2.txt  ...   \n1             2  Article   ./eb07_TXT_v2/a2/kp-eb0702-000101-9822-v2.txt  ...   \n2             3  Article   ./eb07_TXT_v2/a2/kp-eb0702-000201-9835-v2.txt  ...   \n3             4  Article   ./eb07_TXT_v2/a2/kp-eb0702-000201-9835-v2.txt  ...   \n4             5  Article   ./eb07_TXT_v2/a2/kp-eb0702-000201-9835-v2.txt  ...   \n...         ...      ...                                             ...  ...   \n23965         4  Article  ./eb07_TXT_v2/z21/kp-eb0721-102704-1077-v2.txt  ...   \n23966         5  Article  ./eb07_TXT_v2/z21/kp-eb0721-102705-1077-v2.txt  ...   \n23967         6  Article  ./eb07_TXT_v2/z21/kp-eb0721-102706-1077-v2.txt  ...   \n23968         7  Article  ./eb07_TXT_v2/z21/kp-eb0721-102707-1077-v2.txt  ...   \n23969         8  Article  ./eb07_TXT_v2/z21/kp-eb0721-102708-1077-v2.txt  ...   \n\n        volumeId                      permanentURL publisherPersons  \\\n0      192984259  https://digital.nls.uk/192984259               []   \n1      192984259  https://digital.nls.uk/192984259               []   \n2      192984259  https://digital.nls.uk/192984259               []   \n3      192984259  https://digital.nls.uk/192984259               []   \n4      192984259  https://digital.nls.uk/192984259               []   \n...          ...                               ...              ...   \n23965  193819045  https://digital.nls.uk/193819045               []   \n23966  193819045  https://digital.nls.uk/193819045               []   \n23967  193819045  https://digital.nls.uk/193819045               []   \n23968  193819045  https://digital.nls.uk/193819045               []   \n23969  193819045  https://digital.nls.uk/193819045               []   \n\n       volumeNum  editionNum numberOfVolumes numberOfTerms supplementTitle  \\\n0              2           7              22           0.0                   \n1              2           7              22           0.0                   \n2              2           7              22           0.0                   \n3              2           7              22           0.0                   \n4              2           7              22           0.0                   \n...          ...         ...             ...           ...             ...   \n23965         21           7              22           0.0                   \n23966         21           7              22           0.0                   \n23967         21           7              22           0.0                   \n23968         21           7              22           0.0                   \n23969         21           7              22           0.0                   \n\n      supplementSubTitle supplementsTo  \n0                                   []  \n1                                   []  \n2                                   []  \n3                                   []  \n4                                   []  \n...                  ...           ...  \n23965                               []  \n23966                               []  \n23967                               []  \n23968                               []  \n23969                               []  \n\n[23970 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>term</th>\n      <th>note</th>\n      <th>alter_names</th>\n      <th>reference_terms</th>\n      <th>definition</th>\n      <th>startsAt</th>\n      <th>endsAt</th>\n      <th>position</th>\n      <th>termType</th>\n      <th>filePath</th>\n      <th>...</th>\n      <th>volumeId</th>\n      <th>permanentURL</th>\n      <th>publisherPersons</th>\n      <th>volumeNum</th>\n      <th>editionNum</th>\n      <th>numberOfVolumes</th>\n      <th>numberOfTerms</th>\n      <th>supplementTitle</th>\n      <th>supplementSubTitle</th>\n      <th>supplementsTo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>The first letter of the alphabet in every know...</td>\n      <td>11</td>\n      <td>12</td>\n      <td>1</td>\n      <td>Article</td>\n      <td>./eb07_TXT_v2/a2/kp-eb0702-000101-9822-v2.txt</td>\n      <td>...</td>\n      <td>192984259</td>\n      <td>https://digital.nls.uk/192984259</td>\n      <td>[]</td>\n      <td>2</td>\n      <td>7</td>\n      <td>22</td>\n      <td>0.0</td>\n      <td></td>\n      <td></td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>as an abbreviation, is likewise of frequent oc...</td>\n      <td>12</td>\n      <td>12</td>\n      <td>2</td>\n      <td>Article</td>\n      <td>./eb07_TXT_v2/a2/kp-eb0702-000101-9822-v2.txt</td>\n      <td>...</td>\n      <td>192984259</td>\n      <td>https://digital.nls.uk/192984259</td>\n      <td>[]</td>\n      <td>2</td>\n      <td>7</td>\n      <td>22</td>\n      <td>0.0</td>\n      <td></td>\n      <td></td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AA</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>a river of the province of Groningen, in the k...</td>\n      <td>12</td>\n      <td>12</td>\n      <td>3</td>\n      <td>Article</td>\n      <td>./eb07_TXT_v2/a2/kp-eb0702-000201-9835-v2.txt</td>\n      <td>...</td>\n      <td>192984259</td>\n      <td>https://digital.nls.uk/192984259</td>\n      <td>[]</td>\n      <td>2</td>\n      <td>7</td>\n      <td>22</td>\n      <td>0.0</td>\n      <td></td>\n      <td></td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AA</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>a river in the province of Overyssel. in the N...</td>\n      <td>12</td>\n      <td>12</td>\n      <td>4</td>\n      <td>Article</td>\n      <td>./eb07_TXT_v2/a2/kp-eb0702-000201-9835-v2.txt</td>\n      <td>...</td>\n      <td>192984259</td>\n      <td>https://digital.nls.uk/192984259</td>\n      <td>[]</td>\n      <td>2</td>\n      <td>7</td>\n      <td>22</td>\n      <td>0.0</td>\n      <td></td>\n      <td></td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AA</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>a river of the province of Antwerp, in the Net...</td>\n      <td>12</td>\n      <td>12</td>\n      <td>5</td>\n      <td>Article</td>\n      <td>./eb07_TXT_v2/a2/kp-eb0702-000201-9835-v2.txt</td>\n      <td>...</td>\n      <td>192984259</td>\n      <td>https://digital.nls.uk/192984259</td>\n      <td>[]</td>\n      <td>2</td>\n      <td>7</td>\n      <td>22</td>\n      <td>0.0</td>\n      <td></td>\n      <td></td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>23965</th>\n      <td>ZWENIGORODKA</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>a circle of the Russian government of Kiew. It...</td>\n      <td>1037</td>\n      <td>1037</td>\n      <td>4</td>\n      <td>Article</td>\n      <td>./eb07_TXT_v2/z21/kp-eb0721-102704-1077-v2.txt</td>\n      <td>...</td>\n      <td>193819045</td>\n      <td>https://digital.nls.uk/193819045</td>\n      <td>[]</td>\n      <td>21</td>\n      <td>7</td>\n      <td>22</td>\n      <td>0.0</td>\n      <td></td>\n      <td></td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>23966</th>\n      <td>ZWICKAU</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>a city of the kingdom of Saxony, the capital o...</td>\n      <td>1037</td>\n      <td>1037</td>\n      <td>5</td>\n      <td>Article</td>\n      <td>./eb07_TXT_v2/z21/kp-eb0721-102705-1077-v2.txt</td>\n      <td>...</td>\n      <td>193819045</td>\n      <td>https://digital.nls.uk/193819045</td>\n      <td>[]</td>\n      <td>21</td>\n      <td>7</td>\n      <td>22</td>\n      <td>0.0</td>\n      <td></td>\n      <td></td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>23967</th>\n      <td>ZWOLLE</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>a city, the capital of the circle of the same ...</td>\n      <td>1037</td>\n      <td>1037</td>\n      <td>6</td>\n      <td>Article</td>\n      <td>./eb07_TXT_v2/z21/kp-eb0721-102706-1077-v2.txt</td>\n      <td>...</td>\n      <td>193819045</td>\n      <td>https://digital.nls.uk/193819045</td>\n      <td>[]</td>\n      <td>21</td>\n      <td>7</td>\n      <td>22</td>\n      <td>0.0</td>\n      <td></td>\n      <td></td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>23968</th>\n      <td>ZYGHUR</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>a town of Hindustan, in the province of Bejapo...</td>\n      <td>1037</td>\n      <td>1037</td>\n      <td>7</td>\n      <td>Article</td>\n      <td>./eb07_TXT_v2/z21/kp-eb0721-102707-1077-v2.txt</td>\n      <td>...</td>\n      <td>193819045</td>\n      <td>https://digital.nls.uk/193819045</td>\n      <td>[]</td>\n      <td>21</td>\n      <td>7</td>\n      <td>22</td>\n      <td>0.0</td>\n      <td></td>\n      <td></td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>23969</th>\n      <td>ZYMOSIMETER</td>\n      <td>formed from ζύμωσις , fermentation, and μέτϑον...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>is the name given to an instrument described b...</td>\n      <td>1037</td>\n      <td>1037</td>\n      <td>8</td>\n      <td>Article</td>\n      <td>./eb07_TXT_v2/z21/kp-eb0721-102708-1077-v2.txt</td>\n      <td>...</td>\n      <td>193819045</td>\n      <td>https://digital.nls.uk/193819045</td>\n      <td>[]</td>\n      <td>21</td>\n      <td>7</td>\n      <td>22</td>\n      <td>0.0</td>\n      <td></td>\n      <td></td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n<p>23970 rows × 40 columns</p>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edition = df[df[\"MMSID\"] == edition_mmsids[0]].reset_index(drop=True)\n",
    "df_edition"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "    term note alter_names        reference_terms  \\\n0  EARTH    0          []                     []   \n1  EARTH    0          []  [FIGURE OF THE EARTH]   \n\n                                          definition  startsAt  endsAt  \\\n0  amongst ancient philosophers, owe of the four ...       401     401   \n1  in Astronomy and Geography, one of the primary...       401     401   \n\n   position termType                                       filePath  ...  \\\n0        13  Article  ./eb07_TXT_v2/e8/kp-eb0708-039107-8218-v2.txt  ...   \n1        14  Article  ./eb07_TXT_v2/e8/kp-eb0708-039107-8218-v2.txt  ...   \n\n    volumeId                      permanentURL publisherPersons  volumeNum  \\\n0  193322688  https://digital.nls.uk/193322688               []          8   \n1  193322688  https://digital.nls.uk/193322688               []          8   \n\n   editionNum numberOfVolumes numberOfTerms supplementTitle  \\\n0           7              22           0.0                   \n1           7              22           0.0                   \n\n  supplementSubTitle supplementsTo  \n0                               []  \n1                               []  \n\n[2 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>term</th>\n      <th>note</th>\n      <th>alter_names</th>\n      <th>reference_terms</th>\n      <th>definition</th>\n      <th>startsAt</th>\n      <th>endsAt</th>\n      <th>position</th>\n      <th>termType</th>\n      <th>filePath</th>\n      <th>...</th>\n      <th>volumeId</th>\n      <th>permanentURL</th>\n      <th>publisherPersons</th>\n      <th>volumeNum</th>\n      <th>editionNum</th>\n      <th>numberOfVolumes</th>\n      <th>numberOfTerms</th>\n      <th>supplementTitle</th>\n      <th>supplementSubTitle</th>\n      <th>supplementsTo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>EARTH</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>amongst ancient philosophers, owe of the four ...</td>\n      <td>401</td>\n      <td>401</td>\n      <td>13</td>\n      <td>Article</td>\n      <td>./eb07_TXT_v2/e8/kp-eb0708-039107-8218-v2.txt</td>\n      <td>...</td>\n      <td>193322688</td>\n      <td>https://digital.nls.uk/193322688</td>\n      <td>[]</td>\n      <td>8</td>\n      <td>7</td>\n      <td>22</td>\n      <td>0.0</td>\n      <td></td>\n      <td></td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>EARTH</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>[FIGURE OF THE EARTH]</td>\n      <td>in Astronomy and Geography, one of the primary...</td>\n      <td>401</td>\n      <td>401</td>\n      <td>14</td>\n      <td>Article</td>\n      <td>./eb07_TXT_v2/e8/kp-eb0708-039107-8218-v2.txt</td>\n      <td>...</td>\n      <td>193322688</td>\n      <td>https://digital.nls.uk/193322688</td>\n      <td>[]</td>\n      <td>8</td>\n      <td>7</td>\n      <td>22</td>\n      <td>0.0</td>\n      <td></td>\n      <td></td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 40 columns</p>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_earth = df[df[\"term\"] == \"EARTH\"].reset_index(drop=True)\n",
    "df_earth"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load EB-Ontology, and import data from NLS dataframe to it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "from rdflib import Graph, URIRef, Namespace\n",
    "\n",
    "# Create a new RDFLib Graph\n",
    "graph = Graph()\n",
    "\n",
    "# Load your ontology file into the graph\n",
    "ontology_file = \"../hto.ttl\"\n",
    "graph.parse(ontology_file, format=\"turtle\")\n",
    "hto = Namespace(\"https://w3id.org/hto#\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph g has 536 statements.\n"
     ]
    }
   ],
   "source": [
    "# Print the number of \"triples\" in the Graph\n",
    "print(f\"Graph g has {len(graph)} statements.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# load metadata\n",
    "import pandas as pd\n",
    "metadata_df = pd.read_json(\"../source_dataframes/eb/nls_metadata_dataframe\", orient=\"index\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from rdflib import Literal, XSD, RDF, RDFS\n",
    "from rdflib.namespace import FOAF, PROV, SDO\n",
    "def create_collection():\n",
    "    collection = URIRef(\"https://w3id.org/hto/WorkCollection/EncyclopaediaBritannica\")\n",
    "    graph.add((collection, RDF.type, hto.WorkCollection))\n",
    "    graph.add((collection, hto.name, Literal(\"Encyclopaedia Britannica Collection\", datatype=XSD.string)))\n",
    "    return collection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "collection = create_collection()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "import regex\n",
    "\n",
    "NON_AZ09_REGEXP = regex.compile('[^\\p{L}\\p{N}]')\n",
    "def name_to_uri_name(name):\n",
    "    uri_name=NON_AZ09_REGEXP.sub('', name)\n",
    "    return uri_name"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# create edition uri list based on edition number\n",
    "from rdflib import URIRef\n",
    "def get_edition_uri_by_number(metadata_df):\n",
    "    edition_uris = {}\n",
    "    metadata_df_without_supplement = metadata_df[metadata_df[\"editionNum\"] > 0]\n",
    "    edition_nums = metadata_df_without_supplement[\"editionNum\"].unique()\n",
    "    for edition_num in edition_nums:\n",
    "        edition_df = metadata_df_without_supplement[metadata_df_without_supplement[\"editionNum\"] == edition_num]\n",
    "        edition_df = edition_df.iloc[0]\n",
    "        edition_uri = URIRef(\"https://w3id.org/hto/Edition/\" + str(edition_df[\"MMSID\"]))\n",
    "        edition_uris[edition_num] = edition_uri\n",
    "\n",
    "    return edition_uris"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "edition_uris = get_edition_uri_by_number(metadata_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "\n",
    "def edition2rdf(edition_info, graph, hto):\n",
    "\n",
    "    # create triples with general datatype\n",
    "    edition = URIRef(\"https://w3id.org/hto/Edition/\"+str(edition_info[\"MMSID\"]))\n",
    "    graph.add((edition, RDF.type, hto.Edition))\n",
    "    graph.add((collection, hto.hadMember, edition))\n",
    "\n",
    "    # check if it is supplement edition\n",
    "    supplmentsTo = edition_info[\"supplementsTo\"]\n",
    "    edition_num = int(edition_info[\"editionNum\"])\n",
    "    if edition_num == 0 and len(supplmentsTo) > 0 and supplmentsTo[0] != '':\n",
    "        edition_title= str(edition_info[\"supplementTitle\"])\n",
    "        subtitle = edition_info[\"supplementSubTitle\"]\n",
    "        for to_edition_num in supplmentsTo:\n",
    "            if to_edition_num in edition_uris.keys():\n",
    "                to_edition_uri = edition_uris[to_edition_num]\n",
    "                graph.add((edition, hto.wasSupplementOf, to_edition_uri))\n",
    "    else:\n",
    "        edition_title= str(edition_info[\"editionTitle\"])\n",
    "        subtitle = edition_info[\"editionSubTitle\"]\n",
    "        graph.add((edition, hto.number, Literal(edition_num, datatype=XSD.int)))\n",
    "\n",
    "    graph.add((edition, hto.title, Literal(edition_title, datatype=XSD.string)))\n",
    "    if subtitle != 0 and subtitle != \"\":\n",
    "        graph.add((edition, hto.subtitle, Literal(edition_info[\"editionSubTitle\"], datatype=XSD.string)))\n",
    "\n",
    "    # publish_year = datetime.strptime(str(edition_info[\"year\"]), \"%Y\")\n",
    "    graph.add((edition, hto.yearPublished, Literal(int(edition_info[\"year\"]), datatype=XSD.int)))\n",
    "    # create a Location instance for printing place\n",
    "    place_name = str(edition_info[\"place\"])\n",
    "    place_uri_name = name_to_uri_name(place_name)\n",
    "    place = URIRef(\"https://w3id.org/hto/Location/\"+place_uri_name)\n",
    "    graph.add((place, RDF.type, hto.Location))\n",
    "    graph.add((place, RDFS.label, Literal(place_name, datatype=XSD.string)))\n",
    "    graph.add((edition, hto.printedAt, place))\n",
    "\n",
    "    graph.add((edition, hto.mmsid, Literal(str(edition_info[\"MMSID\"]), datatype=XSD.string)))\n",
    "    graph.add((edition, hto.physicalDescription, Literal(edition_info[\"physicalDescription\"], datatype=XSD.string)))\n",
    "    graph.add((edition, hto.genre, Literal(edition_info[\"genre\"], datatype=XSD.string)))\n",
    "    graph.add((edition, hto.language, Literal(edition_info[\"language\"], datatype=XSD.string)))\n",
    "\n",
    "    # create a Location instance for shelf locator\n",
    "    shelf_locator_name = str(edition_info[\"shelfLocator\"])\n",
    "    shelf_locator_uri_name = name_to_uri_name(shelf_locator_name)\n",
    "    shelf_locator = URIRef(\"https://w3id.org/hto/Location/\"+shelf_locator_uri_name)\n",
    "    graph.add((shelf_locator, RDF.type, hto.Location))\n",
    "    graph.add((shelf_locator, RDFS.label, Literal(shelf_locator_name, datatype=XSD.string)))\n",
    "    graph.add((edition, hto.shelfLocator, shelf_locator))\n",
    "\n",
    "    ## Editor\n",
    "    if edition_info[\"editor\"] != 0:\n",
    "        editor_name=str(edition_info[\"editor\"])\n",
    "        editor_uri_name = name_to_uri_name(editor_name)\n",
    "        if editor_name != \"\":\n",
    "            editor = URIRef(\"https://w3id.org/hto/Person/\"+str(editor_uri_name))\n",
    "            graph.add((editor, RDF.type, hto.Person))\n",
    "            graph.add((editor, FOAF.name, Literal(editor_name, datatype=XSD.string)))\n",
    "\n",
    "        if edition_info[\"editor_date\"]!=0:\n",
    "            tmpDate=edition_info[\"editor_date\"].split(\"-\")\n",
    "            birthYear=int(tmpDate[0])\n",
    "            deathYear=int(tmpDate[1])\n",
    "            graph.add((editor, hto.birthYear, Literal(birthYear, datatype=XSD.int)))\n",
    "            graph.add((editor, hto.deathYear, Literal(deathYear, datatype=XSD.int)))\n",
    "\n",
    "        if edition_info[\"termsOfAddress\"] != 0:\n",
    "            graph.add((editor, hto.termsOfAddress, Literal(edition_info[\"termsOfAddress\"], datatype=XSD.string)))\n",
    "\n",
    "        graph.add((edition, hto.editor, editor))\n",
    "\n",
    "    #### Publishers Persons\n",
    "\n",
    "    #This was the result to pass entity recognition to publisher\n",
    "\n",
    "    if edition_info[\"publisherPersons\"] != 0 and len(edition_info[\"publisherPersons\"]) > 0:\n",
    "        publisherPersons=edition_info[\"publisherPersons\"]\n",
    "        print(publisherPersons)\n",
    "        if len(publisherPersons) == 1:\n",
    "            publisher_name = publisherPersons[0]\n",
    "            iri_publisher_name = name_to_uri_name(publisher_name)\n",
    "            if iri_publisher_name != \"\":\n",
    "                publisher = URIRef(\"https://w3id.org/hto/Person/\"+iri_publisher_name)\n",
    "                graph.add((publisher, RDF.type, hto.Person))\n",
    "        else:\n",
    "            iri_publisher_name = \"\"\n",
    "            publisher_name = \"\"\n",
    "            for p in publisherPersons:\n",
    "                publisher_name = publisher_name + \", \" + p\n",
    "                iri_publisher_name= name_to_uri_name(publisher_name)\n",
    "                if iri_publisher_name == \"\":\n",
    "                    break\n",
    "            publisher = URIRef(\"https://w3id.org/hto/Organization/\"+iri_publisher_name)\n",
    "            graph.add((publisher, RDF.type, hto.Organization))\n",
    "\n",
    "        graph.add((publisher, FOAF.name, Literal(publisher_name, datatype=XSD.string)))\n",
    "        graph.add((edition, hto.publisher, publisher))\n",
    "\n",
    "        # Creat an instance of publicationActivity\n",
    "        #publication_activity = URIRef(\"https://w3id.org/hto/Activity/\"+ \"publication\" + str(edition_info[\"MMSID\"]))\n",
    "        #graph.add((publication_activity, RDF.type, PROV.Activity))\n",
    "        #graph.add((publication_activity, PROV.generated, edition))\n",
    "        #graph.add((publication_activity, PROV.endedAtTime, Literal(publish_year, datatype=XSD.dateTime)))\n",
    "        #graph.add((publication_activity, PROV.wasEndedBy, publisher))\n",
    "        #graph.add((edition, PROV.wasGeneratedBy, publication_activity))\n",
    "\n",
    "    #### Is Referenced by\n",
    "\n",
    "    if edition_info[\"referencedBy\"] != 0:\n",
    "        references=edition_info[\"referencedBy\"]\n",
    "        for r in references:\n",
    "            book_name = str(r)\n",
    "            book_uri_name = name_to_uri_name(book_name)\n",
    "            book = URIRef(\"https://w3id.org/hto/Book/\"+book_uri_name)\n",
    "            graph.add((book, RDF.type, hto.Book))\n",
    "            graph.add((book, hto.name, Literal(book_name, datatype=XSD.string)))\n",
    "            graph.add((edition, hto.referencedBy, book))\n",
    "\n",
    "    return edition"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def volume2rdf(volume_info, edition, graph, hto):\n",
    "    volume_id=str(volume_info[\"volumeId\"])\n",
    "    volume = URIRef(\"https://w3id.org/hto/Volume/\"+str(volume_info[\"MMSID\"])+\"_\"+str(volume_id))\n",
    "    graph.add((volume, RDF.type, hto.Volume))\n",
    "    graph.add((volume, hto.number, Literal(volume_info[\"volumeNum\"], datatype=XSD.integer)))\n",
    "    if volume_info[\"letters\"] != 0 and volume_info[\"letters\"] != \"\":\n",
    "        graph.add((volume, hto.letters, Literal(volume_info[\"letters\"], datatype=XSD.string)))\n",
    "    graph.add((volume, hto.volumeId, Literal(volume_id, datatype=XSD.string)))\n",
    "    graph.add((volume, hto.title, Literal(volume_info[\"volumeTitle\"], datatype=XSD.string)))\n",
    "\n",
    "    if volume_info[\"part\"]!=0:\n",
    "        graph.add((volume, hto.part, Literal(volume_info[\"part\"], datatype=XSD.integer)))\n",
    "\n",
    "    permanentURL = URIRef(str(volume_info[\"permanentURL\"]))\n",
    "    graph.add((permanentURL, RDF.type, hto.Location))\n",
    "    graph.add((volume, hto.permanentURL, permanentURL))\n",
    "    # graph.add((volume, hto.numberOfPages, Literal(volume_info[\"numberOfPages\"], datatype=XSD.integer)))\n",
    "    graph.add((edition, RDF.type, hto.WorkCollection))\n",
    "    graph.add((edition, hto.hadMember, volume))\n",
    "    graph.add((volume, hto.wasMemberOf, edition))\n",
    "\n",
    "    return volume"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def get_term_class_name_and_term_ref(term_type, term_id, hto):\n",
    "    term_ref = URIRef(\"https://w3id.org/hto/\" + term_type + \"/\" + term_id)\n",
    "    term_class_name = hto.ArticleTermRecord\n",
    "    if term_type == \"TopicTermRecord\":\n",
    "        term_class_name = hto.TopicTermRecord\n",
    "    return term_class_name, term_ref"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def get_source_ref(filePath, agent):\n",
    "    if agent == \"NCKP\":\n",
    "        parts = filePath.split(\"/\")\n",
    "        if len(parts) < 3:\n",
    "            raise Exception(\"Wrong input format\")\n",
    "        edition_parts = parts[-3].split(\"_\", 1)\n",
    "        file_uri = \"https://raw.githubusercontent.com/TU-plogan/kp-editions/main/\" + edition_parts[0] + \"/\" +  edition_parts[1] + \"/\" +  parts[-2] + \"/\" + parts[-1]\n",
    "        source_ref = URIRef(file_uri)\n",
    "    else:\n",
    "        source_uri_name = filePath.replace(\"/\", \"_\").replace(\".\", \"_\")\n",
    "        source_ref = URIRef(\"https://w3id.org/hto/InformationResource/\" + source_uri_name)\n",
    "    return source_ref"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://raw.githubusercontent.com/TU-plogan/kp-editions/main/eb07/TXT_v2/e8/kp-eb0708-039107-8218-v2.txt\n",
      "https://w3id.org/hto/InformationResource/144133901_alto_188082904_34_xml\n"
     ]
    }
   ],
   "source": [
    "# test function get_source_ref\n",
    "test_get_source_ref_inputs = [\n",
    "    {\"filePath\": \"./eb07_TXT_v2/e8/kp-eb0708-039107-8218-v2.txt\", \"agent\": \"NCKP\"},\n",
    "    {\"filePath\": \"144133901/alto/188082904.34.xml\", \"agent\": \"NLS\"}\n",
    "]\n",
    "for input in test_get_source_ref_inputs:\n",
    "    print(get_source_ref(input[\"filePath\"], input[\"agent\"]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "<Graph identifier=N871334772dad4f2a9cfbf10a516d7cb5 (<class 'rdflib.graph.Graph'>)>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create software uris\n",
    "defoe = URIRef(\"https://github.com/defoe-code/defoe\")\n",
    "graph.add((defoe, RDF.type, hto.SoftwareAgent))\n",
    "frances_information_extraction = URIRef(\"https://github.com/frances-ai/frances-InformationExtraction\")\n",
    "graph.add((frances_information_extraction, RDF.type, hto.SoftwareAgent))\n",
    "ABBYYFineReader = URIRef(\"https://pdf.abbyy.com\")\n",
    "graph.add((ABBYYFineReader, RDF.type, hto.SoftwareAgent))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def link_entity_with_software(graph, entity, entity_type, agent):\n",
    "    software = None\n",
    "    if entity_type == \"description\":\n",
    "        if agent == \"NLS\":\n",
    "            software = defoe\n",
    "        else:\n",
    "            software = frances_information_extraction\n",
    "    else:\n",
    "        if agent == \"NCKP\":\n",
    "            software = ABBYYFineReader\n",
    "\n",
    "    if software:\n",
    "        graph.add((entity, PROV.wasAttributedTo, software))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "previous_edition = {}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "import re\n",
    "# dataframe_to_RDF()\n",
    "def dataframe_to_rdf(dataframe, graph, hto, agent_uri, agent, eb_dataset):\n",
    "    dataframe=dataframe.fillna(0)\n",
    "    dataframe[\"id\"] = dataframe.index\n",
    "    # create triples\n",
    "    edition_mmsids = dataframe[\"MMSID\"].unique()\n",
    "\n",
    "    for mmsid in edition_mmsids:\n",
    "        df_edition = dataframe[dataframe[\"MMSID\"] == mmsid].reset_index(drop=True)\n",
    "\n",
    "        edition_num = int(df_edition.loc[0, \"editionNum\"])\n",
    "        year_published = int(df_edition.loc[0, \"year\"])\n",
    "\n",
    "        #if edition_num == 1 and year_published == 1771 and agent == \"NLS\":\n",
    "            #continue\n",
    "        # exchange the column volume title with edition title, note that this should be done when extract the metadata. This should be removed when it is fixed during information extraction.\n",
    "        if edition_num > 0:\n",
    "            df_edition.rename(columns={'editionTitle': 'volumeTitle', 'volumeTitle': 'editionTitle'}, inplace=True)\n",
    "\n",
    "        edition_info = df_edition.loc[0]\n",
    "        edition_ref = edition2rdf(edition_info, graph, hto)\n",
    "\n",
    "        if edition_num != 0:\n",
    "            # not supplement\n",
    "            if edition_num in previous_edition.keys():\n",
    "                # add revision info\n",
    "                if previous_edition[edition_num][\"year\"] < year_published:\n",
    "                    print(\"revision\")\n",
    "                    graph.add((edition_ref, PROV.wasRevisionOf, previous_edition[edition_num][\"uri\"]))\n",
    "                elif previous_edition[edition_num][\"year\"] > year_published:\n",
    "                    graph.add((previous_edition[edition_num][\"uri\"], PROV.wasRevisionOf, edition_ref))\n",
    "                else:\n",
    "                    print(\"equal\")\n",
    "            else:\n",
    "                previous_edition[edition_num] = {\n",
    "                    \"year\": year_published,\n",
    "                    \"uri\": edition_ref\n",
    "                }\n",
    "\n",
    "        # VOLUMES\n",
    "        vol_numbers = df_edition[\"volumeNum\"].unique()\n",
    "        # graph.add((edition_ref, hto.numberOfVolumes, Literal(len(vol_numbers), datatype=XSD.integer)))\n",
    "        for vol_number in vol_numbers:\n",
    "            df_vol = df_edition[df_edition[\"volumeNum\"] == vol_number].reset_index(drop=True)\n",
    "            volume_info = df_vol.loc[0]\n",
    "            volume_ref = volume2rdf(volume_info, edition_ref, graph, hto)\n",
    "            # print(volume_info)\n",
    "            df_vol_by_term=df_vol.groupby(['term'],)[\"term\"].count().reset_index(name='counts')\n",
    "            # print(df_vol_by_term)\n",
    "\n",
    "            #### TERMS\n",
    "            for t_index in range(0, len(df_vol_by_term)):\n",
    "                term=df_vol_by_term.loc[t_index][\"term\"]\n",
    "                term_counts=df_vol_by_term.loc[t_index][\"counts\"]\n",
    "                term_uri_name = name_to_uri_name(term)\n",
    "                # print(term_uri_name)\n",
    "                # All terms in one volume with name equals to value of term\n",
    "                df_entries= df_vol[df_vol[\"term\"] == term].reset_index(drop=True)\n",
    "                for t_count in range(0, term_counts):\n",
    "                    df_entry= df_entries.loc[t_count]\n",
    "                    term_id = str(mmsid)+\"_\"+str(df_entry[\"volumeId\"])+\"_\"+term_uri_name+\"_\"+str(t_count)\n",
    "                    term_type = str(df_entry[\"termType\"]) + \"TermRecord\"\n",
    "\n",
    "                    term_class_name, term_ref = get_term_class_name_and_term_ref(term_type, term_id, hto)\n",
    "\n",
    "                    # Add the term_ref to dataframe\n",
    "                    dataframe_equal = (dataframe['id'] == df_entry['id'])\n",
    "                    dataframe.loc[dataframe_equal, \"uri\"] = term_ref\n",
    "\n",
    "                    graph.add((term_ref, RDF.type, term_class_name))\n",
    "                    graph.add((term_ref, hto.name, Literal(term, datatype=XSD.string)))\n",
    "                    if \"note\" in df_entry:\n",
    "                        note = df_entry[\"note\"]\n",
    "                        if note != 0:\n",
    "                            graph.add((term_ref, hto.note, Literal(note, datatype=XSD.string)))\n",
    "\n",
    "                    if \"alter_names\" in df_entry:\n",
    "                        alter_names = df_entry[\"alter_names\"]\n",
    "                        for alter_name in alter_names:\n",
    "                            graph.add((term_ref, hto.name, Literal(alter_name, datatype=XSD.string)))\n",
    "\n",
    "                    # Create original description instance\n",
    "                    description = df_entry[\"definition\"]\n",
    "                    if description != \"\":\n",
    "\n",
    "                        term_original_description = URIRef(\"https://w3id.org/hto/OriginalDescription/\" + str(df_entry[\"MMSID\"])+\"_\"+str(df_entry[\"volumeId\"])+\"_\"+term_uri_name+\"_\"+str(t_count)+agent)\n",
    "                        graph.add((term_original_description, RDF.type, hto.OriginalDescription))\n",
    "                        text_quality = hto.Low\n",
    "                        if agent == \"Ash\":\n",
    "                            text_quality = hto.Moderate\n",
    "                        elif agent == \"NCKP\":\n",
    "                            text_quality = hto.High\n",
    "                        graph.add((term_original_description, hto.hasTextQuality, text_quality))\n",
    "                        # graph.add((term_original_description, hto.numberOfWords, Literal(df_entry[\"numberOfWords\"], datatype=XSD.int)))\n",
    "                        graph.add((term_original_description, hto.text, Literal(df_entry[\"definition\"], datatype=XSD.string)))\n",
    "\n",
    "                        graph.add((term_ref, hto.hasOriginalDescription, term_original_description))\n",
    "                        graph.add((term_ref, hto.position, Literal(df_entry[\"position\"], datatype=XSD.int)))\n",
    "\n",
    "                        link_entity_with_software(graph, term_original_description, \"description\", agent)\n",
    "\n",
    "                        # Create source entity where original description was extracted\n",
    "                        # source location\n",
    "                        # source_path_name = df_entry[\"altoXML\"]\n",
    "                        # source_path_ref = URIRef(\"https://w3id.org/eb/Location/\" + source_path_name)\n",
    "                        # graph.add((source_path_ref, RDF.type, PROV.Location))\n",
    "                        # source\n",
    "                        file_path = str(df_entry[\"filePath\"])\n",
    "                        source_ref = get_source_ref(file_path, agent)\n",
    "                        graph.add((source_ref, RDF.type, hto.InformationResource))\n",
    "                        graph.add((source_ref, PROV.value, Literal(file_path, datatype=XSD.string)))\n",
    "                        graph.add((eb_dataset, hto.hadMember, source_ref))\n",
    "                        graph.add((source_ref, PROV.wasAttributedTo, agent_uri))\n",
    "                        link_entity_with_software(graph, source_ref, \"source\", agent)\n",
    "\n",
    "                        #graph.add((source_ref, PROV.atLocation, source_path_ref))\n",
    "                        # related agent and activity\n",
    "\n",
    "\n",
    "                        \"\"\"\n",
    "                        source_digitalising_activity = URIRef(\"https://w3id.org/eb/Activity/nls_digitalising_activity\" + source_name)\n",
    "                        graph.add((source_digitalising_activity, RDF.type, PROV.Activity))\n",
    "                        graph.add((source_digitalising_activity, PROV.generated, source_ref))\n",
    "                        graph.add((source_digitalising_activity, PROV.wasAssociatedWith, nls))\n",
    "                        graph.add((source_ref, PROV.wasGeneratedBy, source_digitalising_activity))\n",
    "                        \"\"\"\n",
    "                        graph.add((term_original_description, hto.wasExtractedFrom, source_ref))\n",
    "\n",
    "                    ## startsAt\n",
    "                    page_startsAt= URIRef(\"https://w3id.org/hto/Page/\"+ str(df_entry[\"MMSID\"])+\"_\"+str(df_entry[\"volumeId\"])+\"_\"+str(df_entry[\"startsAt\"]))\n",
    "                    graph.add((page_startsAt, RDF.type, hto.Page))\n",
    "                    graph.add((page_startsAt, hto.number, Literal(df_entry[\"startsAt\"], datatype=XSD.int)))\n",
    "                    if df_entry[\"header\"] != 0 and df_entry[\"header\"] != \"\":\n",
    "                        graph.add((page_startsAt, hto.header, Literal(df_entry[\"header\"], datatype=XSD.string)))\n",
    "                    # graph.add((page_startsAt, hto.numberOfTerms, Literal(df_entry[\"numberOfTerms\"], datatype=XSD.int)))\n",
    "                    graph.add((volume_ref, RDF.type, hto.WorkCollection))\n",
    "                    graph.add((volume_ref, hto.hadMember, page_startsAt))\n",
    "                    graph.add((term_ref, hto.startsAtPage, page_startsAt))\n",
    "                    graph.add((page_startsAt, RDF.type, hto.WorkCollection))\n",
    "                    graph.add((page_startsAt, hto.hadMember, term_ref))\n",
    "\n",
    "                    ## endsAt\n",
    "                    page_endsAt= URIRef(\"https://w3id.org/hto/Page/\"+ str(df_entry[\"MMSID\"])+\"_\"+str(df_entry[\"volumeId\"])+\"_\"+str(df_entry[\"endsAt\"]))\n",
    "                    graph.add((page_endsAt, RDF.type, hto.Page))\n",
    "                    graph.add((page_endsAt, hto.number, Literal(df_entry[\"endsAt\"], datatype=XSD.int)))\n",
    "                    # graph.add((page_endsAt, hto.numberOfTerms, Literal(df_entry[\"numberOfTerms\"], datatype=XSD.int)))\n",
    "                    graph.add((volume_ref, hto.hadMember, page_endsAt))\n",
    "                    graph.add((term_ref, hto.endsAtPage, page_endsAt))\n",
    "                    graph.add((page_endsAt, RDF.type, hto.WorkCollection))\n",
    "                    graph.add((page_endsAt, hto.hadMember, term_ref))\n",
    "\n",
    "    return graph, dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from rdflib import Literal, XSD, RDF\n",
    "from rdflib.namespace import FOAF, PROV, SDO\n",
    "# create organization NCKP\n",
    "agents = {\n",
    "    \"NCKP\": [\"Nineteen Century Knowledge Project\", hto.Organization],\n",
    "    \"Ash\": [\"Ash Charlton\", hto.Person],\n",
    "    \"NLS\": [\"National Library of Scotland\", hto.Organization]\n",
    "}\n",
    "\n",
    "def create_organization(graph, agent):\n",
    "    agent_uri = URIRef(\"https://w3id.org/hto/Organization/\" + agent)\n",
    "    graph.add((agent_uri, RDF.type, agents[agent][1]))\n",
    "    graph.add((agent_uri, FOAF.name, Literal(agents[agent][0], datatype=XSD.string)))\n",
    "    return agent_uri"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "def create_eb_text_dataset(graph, agent_uri, agent):\n",
    "    eb_text_dataset = URIRef(\"https://w3id.org/hto/Collection/\" + agent + \"_eb_dataset\")\n",
    "    graph.add((eb_text_dataset, RDF.type, PROV.Collection))\n",
    "    graph.add((eb_text_dataset, PROV.wasAttributedTo, agent_uri))\n",
    "\n",
    "    # Create digitalising activity\n",
    "    digitalising_activity = URIRef(\"https://w3id.org/hto/Activity/\" + agent + \"_digitalising_activity\")\n",
    "    graph.add((digitalising_activity, RDF.type, hto.Activity))\n",
    "    graph.add((digitalising_activity, PROV.generated, eb_text_dataset))\n",
    "    graph.add((digitalising_activity, PROV.wasAssociatedWith, agent_uri))\n",
    "    graph.add((eb_text_dataset, PROV.wasGeneratedBy, digitalising_activity))\n",
    "    return eb_text_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['C. Macfarquhar', 'Colin Macfarquhar']\n",
      "['John Donaldson']\n",
      "revision\n",
      "2\n",
      "['W. Gordon', 'J. Bell', 'J. Dickson', 'C. Elliot']\n",
      "3\n",
      "['C. Macfarquhar']\n",
      "['J. Brown']\n",
      "4\n",
      "4 5 6\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "datetime_with_uris_list = []\n",
    "\n",
    "#print(1)\n",
    "# Ash Edition 1\n",
    "#agent = \"Ash\"\n",
    "#agent_uri = create_organization(graph, agent)\n",
    "#eb_text_dataset = create_eb_text_dataset(graph, agent_uri, agent)\n",
    "# import data from 1st edition\n",
    "#df_1= pd.read_json('../source_dataframes/eb/ash_final_eb_1_dataframe_clean_Damon', orient=\"index\")\n",
    "#graph, dataframe_with_uris = dataframe_to_rdf(df_1, graph, hto,  agent_uri, agent, eb_text_dataset)\n",
    "\n",
    "print(1)\n",
    "\n",
    "# NLS Edition 1\n",
    "agent = \"NLS\"\n",
    "agent_uri = create_organization(graph, agent)\n",
    "eb_text_dataset = create_eb_text_dataset(graph, agent_uri, agent)\n",
    "# import data from 1st edition\n",
    "df_1= pd.read_json('../source_dataframes/eb/final_eb_1_dataframe', orient=\"index\")\n",
    "df_1.rename(columns={\"typeTerm\": \"termType\", \"positionPage\": \"position\", \"altoXML\": \"filePath\"}, inplace=True)\n",
    "graph, dataframe_with_uris = dataframe_to_rdf(df_1, graph, hto,  agent_uri, agent, eb_text_dataset)\n",
    "datetime_with_uris_list.append(dataframe_with_uris)\n",
    "\n",
    "print(2)\n",
    "\n",
    "# NLS Edition 2\n",
    "\n",
    "# import data from 2snd edition\n",
    "df_2= pd.read_json('../source_dataframes/eb/final_eb_2_dataframe', orient=\"index\")\n",
    "df_2.rename(columns={\"typeTerm\": \"termType\", \"positionPage\": \"position\", \"altoXML\": \"filePath\"}, inplace=True)\n",
    "graph, dataframe_with_uris = dataframe_to_rdf(df_2, graph, hto,  agent_uri, agent, eb_text_dataset)\n",
    "datetime_with_uris_list.append(dataframe_with_uris)\n",
    "\n",
    "print(3)\n",
    "\n",
    "# NLS Edition 3\n",
    "# import data from 3rd edition\n",
    "df_3= pd.read_json('../source_dataframes/eb/final_eb_3_dataframe', orient=\"index\")\n",
    "df_3.rename(columns={\"typeTerm\": \"termType\", \"positionPage\": \"position\", \"altoXML\": \"filePath\"}, inplace=True)\n",
    "graph, dataframe_with_uris = dataframe_to_rdf(df_3, graph, hto,  agent_uri, agent, eb_text_dataset)\n",
    "datetime_with_uris_list.append(dataframe_with_uris)\n",
    "\n",
    "print(4)\n",
    "# NLS Edition 4\n",
    "# import data from 4th edition\n",
    "df_4= pd.read_json('../source_dataframes/eb/final_eb_4_dataframe', orient=\"index\")\n",
    "df_4.rename(columns={\"typeTerm\": \"termType\", \"positionPage\": \"position\", \"altoXML\": \"filePath\"}, inplace=True)\n",
    "graph, dataframe_with_uris = dataframe_to_rdf(df_4, graph, hto,  agent_uri, agent, eb_text_dataset)\n",
    "datetime_with_uris_list.append(dataframe_with_uris)\n",
    "\n",
    "print(4, 5, 6)\n",
    "# NLS Edition 4, 5, 6\n",
    "df_456= pd.read_json('../source_dataframes/eb/final_eb_4_5_6_suplement_dataframe', orient=\"index\")\n",
    "df_456.rename(columns={\"typeTerm\": \"termType\", \"positionPage\": \"position\", \"altoXML\": \"filePath\"}, inplace=True)\n",
    "graph, dataframe_with_uris = dataframe_to_rdf(df_456, graph, hto,  agent_uri, agent, eb_text_dataset)\n",
    "datetime_with_uris_list.append(dataframe_with_uris)\n",
    "\n",
    "print(5)\n",
    "# NLS Edition 5\n",
    "# import data from 5st edition\n",
    "df_5= pd.read_json('../source_dataframes/eb/final_eb_5_dataframe', orient=\"index\")\n",
    "df_5.rename(columns={ \"typeTerm\": \"termType\", \"positionPage\": \"position\", \"altoXML\": \"filePath\"}, inplace=True)\n",
    "graph, dataframe_with_uris = dataframe_to_rdf(df_5, graph, hto,  agent_uri, agent, eb_text_dataset)\n",
    "datetime_with_uris_list.append(dataframe_with_uris)\n",
    "\n",
    "print(6)\n",
    "# NLS Edition 6\n",
    "# import data from 6st edition\n",
    "df_6= pd.read_json('../source_dataframes/eb/final_eb_6_dataframe', orient=\"index\")\n",
    "df_6.rename(columns={\"typeTerm\": \"termType\", \"positionPage\": \"position\", \"altoXML\": \"filePath\"}, inplace=True)\n",
    "graph, dataframe_with_uris = dataframe_to_rdf(df_6, graph, hto,  agent_uri, agent, eb_text_dataset)\n",
    "datetime_with_uris_list.append(dataframe_with_uris)\n",
    "\n",
    "print(7)\n",
    "# NLS Edition 7\n",
    "#agent = \"NLS\"\n",
    "#agent_uri = create_organization(graph, agent)\n",
    "#eb_text_dataset = create_eb_text_dataset(graph, agent_uri, agent)\n",
    "# import data from 1st edition\n",
    "df_7= pd.read_json('../source_dataframes/eb/final_eb_7_dataframe', orient=\"index\")\n",
    "df_7.rename(columns={\"typeTerm\": \"termType\", \"positionPage\": \"position\", \"altoXML\": \"filePath\"}, inplace=True)\n",
    "graph, dataframe_with_uris = dataframe_to_rdf(df_7, graph, hto,  agent_uri, agent, eb_text_dataset)\n",
    "datetime_with_uris_list.append(dataframe_with_uris)\n",
    "\n",
    "print(8)\n",
    "# NLS Edition 8\n",
    "# import data from 3rd edition\n",
    "df_8= pd.read_json('../source_dataframes/eb/final_eb_8_dataframe', orient=\"index\")\n",
    "df_8.rename(columns={\"typeTerm\": \"termType\", \"positionPage\": \"position\", \"altoXML\": \"filePath\"}, inplace=True)\n",
    "graph, dataframe_with_uris = dataframe_to_rdf(df_8, graph, hto,  agent_uri, agent, eb_text_dataset)\n",
    "datetime_with_uris_list.append(dataframe_with_uris)\n",
    "\n",
    "#print(7)\n",
    "# NCKP Edition 7\n",
    "#agent = \"NCKP\"\n",
    "#agent_uri = create_organization(graph, agent)\n",
    "#eb_text_dataset = create_eb_text_dataset(graph, agent_uri, agent)\n",
    "# import data from 7st edition\n",
    "#df_7 = pd.read_json('../source_dataframes/eb/nckp_final_eb_7_dataframe_clean_Damon', orient=\"index\")\n",
    "#graph, dataframe_with_uris = dataframe_to_rdf(df_7, graph, hto,  agent_uri, agent, eb_text_dataset)\n",
    "\n",
    "dataframe_with_uris_total = pd.concat(datetime_with_uris_list, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "MMSID                                                    992277653804341\neditionTitle                          First edition, 1771, Volume 1, A-B\neditor                                                  Smellie, William\neditor_date                                                    1740-1795\ngenre                                                       encyclopedia\nlanguage                                                             eng\ntermsOfAddress                                                       0.0\nnumberOfPages                                                        832\nphysicalDescription               3 v., 160 plates : ill. ; 26 cm. (4to)\nplace                                                          Edinburgh\npublisher              Printed for A. Bell and C. Macfarquhar; and so...\nreferencedBy           [Alston, R.C.  Engl. language III, 560, ESTC T...\nshelfLocator                                                        EB.1\neditionSubTitle        Illustrated with one hundred and sixty copperp...\nvolumeTitle            Encyclopaedia Britannica; or, A dictionary of ...\nyear                                                                1771\nvolumeId                                                       144133901\nmetsXML                                               144133901-mets.xml\npermanentURL                            https://digital.nls.uk/144133901\npublisherPersons                     [C. Macfarquhar, Colin Macfarquhar]\nvolumeNum                                                              1\nletters                                                              A-B\npart                                                                   0\neditionNum                                                             1\nsupplementTitle                                                         \nsupplementSubTitle                                                      \nsupplementsTo                                                         []\nnumberOfVolumes                                                        6\nterm                                                                  OR\ndefinition             A NEW A D I C T I A A, the name of several riv...\nrelatedTerms                                                          []\nheader                                                              EBAA\nstartsAt                                                              15\nendsAt                                                                15\nnumberOfTerms                                                         22\nnumberOfWords                                                         54\nposition                                                               0\ntermType                                                         Article\nfilePath                                 144133901/alto/188082904.34.xml\nid                                                                     0\nuri                    https://w3id.org/hto/ArticleTermRecord/9922776...\nName: 0, dtype: object"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_with_uris_total.iloc[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# store the new dataframe with uris\n",
    "dataframe_with_uris_total.to_json('./final_eb_total_dataframe_lq_with_uris', orient=\"index\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "<Graph identifier=N871334772dad4f2a9cfbf10a516d7cb5 (<class 'rdflib.graph.Graph'>)>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the Graph in the RDF Turtle format\n",
    "graph.serialize(format=\"turtle\", destination=\"../../results/hto_eb_total_lq.ttl\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
